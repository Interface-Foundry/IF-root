{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(s, tokenize_words=False):\n",
    "    s = s.lower()\n",
    "    s = s.replace('-', ' ')\n",
    "    s = ''.join(x for x in s if x not in [',', 'Â®', ':', '+', '%', '#'])\n",
    "    s = s.replace('mm', ' mm')\n",
    "    s = re.sub(r'\\([^)]*\\)', '', s)\n",
    "    s = re.sub(r'\\[[^)]*\\]', '', s)\n",
    "    s = s.replace('/', ' ')\n",
    "    s = s.replace('gold edition', 'gold_edition')\n",
    "    s = s.replace('premium edition', 'premium_edition')\n",
    "    s = s.replace('standard edition', 'standard_edition')\n",
    "    s = s.replace('feet', ' feet')\n",
    "    s = s.strip()\n",
    "    if tokenize_words:\n",
    "        stoplist = ['&', 'a', 'and', 'the', 'for', 'of', 'to', 'in', 'into']\n",
    "        s = [word for word in s.split() if word not in stoplist]\n",
    "        s = word_tokenize(' '.join(s))\n",
    "    return s\n",
    "\n",
    "def normalize_in_list(row, type='cat'):\n",
    "    tmp = []\n",
    "    for x in row:\n",
    "        if type == 'cat':\n",
    "            tmp.append(preprocess(x, tokenize_words=False))\n",
    "        if type == 'item':\n",
    "            tmp.append(preprocess(x, tokenize_words=True))\n",
    "    return tmp\n",
    "\n",
    "def flatten_lists(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = {}\n",
    "\n",
    "with open('amazon-meta.txt', 'r') as f:\n",
    "    line = f.readline()\n",
    "    asin = ''\n",
    "    product = {\n",
    "        'asin': '',\n",
    "        'title': '',\n",
    "        'group': '',\n",
    "        'similar': [],\n",
    "        'categories': []\n",
    "    }\n",
    "    index = 0\n",
    "    \n",
    "    while line:\n",
    "        if ('ASIN: ' in line[:6]):\n",
    "            product['asin'] = line[6:].strip()\n",
    "            product['title'] = ''\n",
    "            product['group'] = ''\n",
    "            product['similar']\n",
    "        elif ('  title: ' == line[:9]):\n",
    "            product['title'] = line[9:].strip()\n",
    "        elif ('  group: ' == line[:9]):\n",
    "            product['group'] = line[9:].strip()\n",
    "        elif ('  similar: ' == line[:11]):\n",
    "            product['similar'] = line.strip().split()[2:]\n",
    "        elif ('  categories: ' in line):\n",
    "            line = f.readline()\n",
    "            while ('|' in line):\n",
    "                product['categories'].append(re.sub(r'\\[.*?\\]', '', line.strip()).split('|')[1:])\n",
    "                line = f.readline()\n",
    "            df[index] = product\n",
    "            \n",
    "            product = {\n",
    "                'asin': '',\n",
    "                'title': '',\n",
    "                'group': '',\n",
    "                'similar': [],\n",
    "                'categories': []\n",
    "            }\n",
    "            \n",
    "            index += 1\n",
    "            \n",
    "        line = f.readline()\n",
    "\n",
    "df = pd.DataFrame.from_dict(df, orient='index')\n",
    "df['title_n'] = df['title'].apply(lambda x: normalize_in_list([x], type='item')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>similar</th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>title_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Book</td>\n",
       "      <td>['0804215715', '156101074X', '0687023955', '06...</td>\n",
       "      <td>0827229534</td>\n",
       "      <td>Patterns of Preaching: A Sermon Sampler</td>\n",
       "      <td>[['Books', 'Subjects', 'Religion &amp; Spiritualit...</td>\n",
       "      <td>['patterns', 'preaching', 'sermon', 'sampler']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book</td>\n",
       "      <td>['0738700827', '1567184960', '1567182836', '07...</td>\n",
       "      <td>0738700797</td>\n",
       "      <td>Candlemas: Feast of Flames</td>\n",
       "      <td>[['Books', 'Subjects', 'Religion &amp; Spiritualit...</td>\n",
       "      <td>['candlemas', 'feast', 'flames']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Book</td>\n",
       "      <td>[]</td>\n",
       "      <td>0486287785</td>\n",
       "      <td>World War II Allied Fighter Planes Trading Cards</td>\n",
       "      <td>[['Books', 'Subjects', 'Home &amp; Garden', 'Craft...</td>\n",
       "      <td>['world', 'war', 'ii', 'allied', 'fighter', 'p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  group                                            similar        asin  \\\n",
       "0  Book  ['0804215715', '156101074X', '0687023955', '06...  0827229534   \n",
       "1  Book  ['0738700827', '1567184960', '1567182836', '07...  0738700797   \n",
       "2  Book                                                 []  0486287785   \n",
       "\n",
       "                                              title  \\\n",
       "0           Patterns of Preaching: A Sermon Sampler   \n",
       "1                        Candlemas: Feast of Flames   \n",
       "2  World War II Allied Fighter Planes Trading Cards   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [['Books', 'Subjects', 'Religion & Spiritualit...   \n",
       "1  [['Books', 'Subjects', 'Religion & Spiritualit...   \n",
       "2  [['Books', 'Subjects', 'Home & Garden', 'Craft...   \n",
       "\n",
       "                                             title_n  \n",
       "0     ['patterns', 'preaching', 'sermon', 'sampler']  \n",
       "1                   ['candlemas', 'feast', 'flames']  \n",
       "2  ['world', 'war', 'ii', 'allied', 'fighter', 'p...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('amazon-metadata.csv', mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('amazon-metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5, \n",
    "                             max_features=None, \n",
    "                             stop_words='english', \n",
    "                             use_idf=True)\n",
    "X = vectorizer.fit_transform(df.title_n)\n",
    "\n",
    "svd = TruncatedSVD(200)\n",
    "normalizer = Normalizer(copy=False)\n",
    "pipe_it_up = make_pipeline(svd, normalizer)\n",
    "X2 = pipe_it_up.fit_transform(X).astype('float32')\n",
    "\n",
    "tags = list(df.group.unique())\n",
    "Y = np_utils.to_categorical(df.group.apply(lambda x: tags.index(x)), len(tags)).astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 332121 samples, validate on 110708 samples\n",
      "Epoch 1/50\n",
      "332121/332121 [==============================] - 3s - loss: nan - acc: 0.7147 - val_loss: nan - val_acc: 0.7437\n",
      "Epoch 2/50\n",
      "332121/332121 [==============================] - 3s - loss: nan - acc: 0.7291 - val_loss: nan - val_acc: 0.7437\n",
      "Epoch 3/50\n",
      "332121/332121 [==============================] - 4s - loss: nan - acc: 0.7291 - val_loss: nan - val_acc: 0.7437\n",
      "Epoch 4/50\n",
      "332121/332121 [==============================] - 4s - loss: nan - acc: 0.7291 - val_loss: nan - val_acc: 0.7437\n",
      "Epoch 5/50\n",
      " 63360/332121 [====>.........................] - ETA: 3s - loss: nan - acc: 0.7265"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-f422157a2a7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m model.fit(X2, Y, batch_size=128, shuffle=True,\n\u001b[1;32m      8\u001b[0m           \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m           validation_split=0.25)\n\u001b[0m",
      "\u001b[0;32m/Users/irwinli/anaconda/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1106\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m                               callback_metrics=callback_metrics)\n\u001b[0m\u001b[1;32m   1109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/irwinli/anaconda/lib/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics)\u001b[0m\n\u001b[1;32m    824\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 826\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    827\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/irwinli/anaconda/lib/python3.4/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/irwinli/anaconda/lib/python3.4/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/irwinli/anaconda/lib/python3.4/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(X2.shape[1],))\n",
    "groups = Dense(Y.shape[1], activation='relu')(inputs)\n",
    "\n",
    "model = Model(input=inputs, output=groups)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X2, Y, batch_size=128, shuffle=True,\n",
    "          nb_epoch=50,  verbose=1, \n",
    "          validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
